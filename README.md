# Automated-Image-Captioning-System

### Table of contents
* [Introduction](#introduction)
* [Technologies](#technologies)
* [Algorithms](#algorithms)
* [Approach](#approach)

### Introduction
Automatically describing the content of an image is one of the challenging problems in Artificial Intelligence where a textual description must be generated for a given image. It requires both methods from computer vision to understand the content of the image and a language model from natural language processing to convert the understanding of the image into words in the correct structure. For this project we have taken Flickr8k dataset which consists of images along with their captions and we implemented our neural network-based image caption generator in Pytorch. For this project we have identified five major components, first one is data pre-processing, second is Encoder part which is the implementation of Convolutional Neural Network model that extracts features from images, third is attention mechanism, fourth is Decoder part which is the implementation of LSTM model which translates the features and objects in the image to a natural sentence and finally using greedy Search we generated the captions for the images. We have chosen BLEU metric to evaluate the quality and the accuracy of the captions generated by the model. We were able to implement the components mentioned above and were able to train our network on Google Colaboratory. Our model was able to achieve a BLEU-4 score of 13.5.

### Data Source
* Kaggle

### Technologies
* [PyTorch]
